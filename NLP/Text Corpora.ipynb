{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.609909212324673 austen-emma.txt\n",
      "4.749793727271801 austen-persuasion.txt\n",
      "4.753785952421314 austen-sense.txt\n",
      "4.286881563819072 bible-kjv.txt\n",
      "4.567033756284415 blake-poems.txt\n",
      "4.489300433741879 bryant-stories.txt\n",
      "4.464641670621737 burgess-busterbrown.txt\n",
      "4.233216065669891 carroll-alice.txt\n",
      "4.716173862839705 chesterton-ball.txt\n",
      "4.724783007796614 chesterton-brown.txt\n",
      "4.63099417739442 chesterton-thursday.txt\n",
      "4.4391184023772565 edgeworth-parents.txt\n",
      "4.76571875515204 melville-moby_dick.txt\n",
      "4.835734572682675 milton-paradise.txt\n",
      "4.347539968257655 shakespeare-caesar.txt\n",
      "4.3597698072805136 shakespeare-hamlet.txt\n",
      "4.336689714779602 shakespeare-macbeth.txt\n",
      "4.591950052620365 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "for fileid in gutenberg.fileids():\n",
    "    n_words=len(gutenberg.words(fileid))\n",
    "    n_chars=len(gutenberg.raw(fileid))\n",
    "    print(n_chars/n_words,fileid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.63538599411087 austen-emma.txt\n",
      "16.00962165688193 austen-persuasion.txt\n",
      "20.719449729255086 austen-sense.txt\n",
      "73.40068269300603 bible-kjv.txt\n",
      "4.59010989010989 blake-poems.txt\n",
      "12.57081447963801 bryant-stories.txt\n",
      "10.75 burgess-busterbrown.txt\n",
      "11.309681697612731 carroll-alice.txt\n",
      "10.841175813121717 chesterton-ball.txt\n",
      "10.37028557657549 chesterton-brown.txt\n",
      "10.167915381225209 chesterton-thursday.txt\n",
      "21.960075054727405 edgeworth-parents.txt\n",
      "13.502044830977896 melville-moby_dick.txt\n",
      "9.00613896381732 milton-paradise.txt\n",
      "7.256460674157303 shakespeare-caesar.txt\n",
      "6.858821369561227 shakespeare-hamlet.txt\n",
      "5.760517799352751 shakespeare-macbeth.txt\n",
      "10.809058552585665 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "for fileid in gutenberg.fileids():\n",
    "    n_words=len(gutenberg.words(fileid))\n",
    "    n_unique_words=[word for word in set(gutenberg.words(fileid))]\n",
    "    n_unique=len(n_unique_words)\n",
    "    print(n_words/n_unique,fileid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "aus_words=[word for word in gutenberg.words('austen-sense.txt')]\n",
    "aus_words_alpha=[word for word in aus_words if word.isalpha()]\n",
    "aus_Words_gt4_z=[word for word in aus_words_alpha if len(word)>4 and 'z' in word]\n",
    "print(len(aus_Words_gt4_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aus_Words_gt4_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus_lower_words=[word.lower() for word in aus_words_alpha]\n",
    "aus_unique_words=[word for word in set(aus_lower_words)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words as wd\n",
    "engcorpus_words=words.words()\n",
    "# for fileid in wd.fileids():\n",
    "#     engcorpus_words+=[wd.words(fileid)]\n",
    "\n",
    "engcorpus_words_2=[word.lower() for word in  engcorpus_words ]\n",
    "engcorpus_unique_words=[word for word in set(engcorpus_words_2)]\n",
    "unusual_words=set(aus_unique_words).difference(set(engcorpus_unique_words))\n",
    "print(len(unusual_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fresco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120733"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aus_words_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6283"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aus_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
